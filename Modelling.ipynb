{"cells":[{"cell_type":"markdown","metadata":{"id":"Bk90c9fY-mbm"},"source":["# Voice Recognition"]},{"cell_type":"markdown","metadata":{"id":"ddRUeP1d-mbp"},"source":["## Audio Modelling"]},{"cell_type":"markdown","source":["### Dependencies if needed"],"metadata":{"id":"2Y66OzyDXya6"}},{"cell_type":"code","source":["!pip install librosa soundfile\n","!pip install datasets\n","!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdsYbsXx-vmy","executionInfo":{"status":"ok","timestamp":1731059660545,"user_tz":-420,"elapsed":18051,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"27f69094-4357-4eae-a5ea-50894606bb68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"d7gIyI-B-mbp"},"source":["### Library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dgpxHv2-mbp"},"outputs":[],"source":["#Library\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset, Audio, DatasetDict, concatenate_datasets\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os\n","import librosa\n","from IPython.display import Audio\n","from scipy.signal import medfilt\n","from dataclasses import dataclass\n","from typing import Any, Dict, List, Union\n","from transformers import WhisperTokenizer, WhisperFeatureExtractor, WhisperProcessor, WhisperForConditionalGeneration\n","#!pip install librosa soundfile (if not installed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wK14zYz4-mbq","executionInfo":{"status":"ok","timestamp":1731062238049,"user_tz":-420,"elapsed":4552,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"deb1edd9-beaf-4f84-a2bc-4314d71e6b16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Requirement already satisfied: GPUtil in /usr/local/lib/python3.10/dist-packages (1.4.0)\n"]},{"output_type":"execute_result","data":{"text/plain":["[0]"]},"metadata":{},"execution_count":2}],"source":["import torch\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")\n","\n","!pip install GPUtil\n","import GPUtil\n","GPUtil.getAvailable()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0GnMrLG9-mbr","executionInfo":{"status":"ok","timestamp":1731062238049,"user_tz":-420,"elapsed":4,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"4e9cd73a-50a6-4891-9e56-3c23a50b4e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDNN VERSION: 90100\n","Number CUDA Devices: 1\n","CUDA Device Name: Tesla T4\n","CUDA Device Total Memory [GB]: 15.835660288\n"]}],"source":["if device:\n","    print('CUDNN VERSION:', torch.backends.cudnn.version())\n","    print('Number CUDA Devices:', torch.cuda.device_count())\n","    print('CUDA Device Name:',torch.cuda.get_device_name(0))\n","    print('CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"]},{"cell_type":"markdown","metadata":{"id":"pIqNb325-mbr"},"source":["### Load Data"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8j7SZ-M_H6o","executionInfo":{"status":"ok","timestamp":1731062240829,"user_tz":-420,"elapsed":2783,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"bb50a812-0e0a-40cf-a59c-0a2410a3667b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lghVoU7R-mbr","executionInfo":{"status":"ok","timestamp":1731062514452,"user_tz":-420,"elapsed":1085,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"1199ec5c-26eb-44bf-8569-114aad81c485"},"outputs":[{"output_type":"stream","name":"stdout","text":["Available splits: dict_keys(['train', 'test', 'validation'])\n"]}],"source":["# Load Dataset\n","minds_us_data = load_dataset('csv', data_files={\n","    'train': '/content/drive/MyDrive/ai-portfolio/project3/datasets_split/minds_traindf.csv',\n","    'test': '/content/drive/MyDrive/ai-portfolio/project3/datasets_split/minds_testdf.csv',\n","    'validation': '/content/drive/MyDrive/ai-portfolio/project3/datasets_split/minds_valdf.csv'\n","})\n","\n","# Print available keys to check what splits are loaded\n","print(\"Available splits:\", minds_us_data.keys())\n","\n","# Combine the datasets into one DatasetDict\n","ds = DatasetDict({\n","    'train': minds_us_data['train'],\n","    'test': minds_us_data.get('test'),  # Use .get() to avoid KeyError if 'test' doesn't exist\n","    'valid': minds_us_data.get('validation')\n","})\n","\n","# Check if 'test' split exists before proceeding\n","if ds['test'] is None:\n","    print(\"Warning: 'test' split not found. Please check your dataset.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBz6isqS-mbs","executionInfo":{"status":"ok","timestamp":1731062515155,"user_tz":-420,"elapsed":2,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"9f3f7635-1919-4f86-d3e4-9c056a3f30bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n","        num_rows: 450\n","    })\n","    test: Dataset({\n","        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n","        num_rows: 57\n","    })\n","    valid: Dataset({\n","        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n","        num_rows: 56\n","    })\n","})\n"]}],"source":["print(ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRQ4WHM3-mbs"},"outputs":[],"source":["# Defining Load Audio\n","def load_audio_data(batch, audio_base_path):\n","    audio_files = [os.path.join(audio_base_path, filepath) for filepath in batch['filepath']]\n","    audio_data = [librosa.load(file_path, sr=None) for file_path in audio_files]\n","\n","    # Separate audio data and sample rates\n","    audio_signals = [data[0] for data in audio_data]\n","    sample_rates = [data[1] for data in audio_data]\n","\n","    batch['audio'] = [{'path': file_path, 'array': audio, 'sampling_rate': sr} for file_path, audio, sr in zip(audio_files, audio_signals, sample_rates)]\n","    return batch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BHClusJN-mbs","executionInfo":{"status":"ok","timestamp":1731062517920,"user_tz":-420,"elapsed":547,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"9a2e44c2-e892-452e-f490-23c2a390eb46"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n","        num_rows: 450\n","    })\n","    test: Dataset({\n","        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n","        num_rows: 57\n","    })\n","    valid: Dataset({\n","        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n","        num_rows: 56\n","    })\n","})\n"]}],"source":["# Load Audio Path\n","audio_base_path = \"/content/drive/MyDrive/ai-portfolio/project3/datasets/MInDS-14/audio\"\n","ds = ds.map(load_audio_data, fn_kwargs={'audio_base_path': audio_base_path}, batched=True)\n","\n","print(ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9pgvzd6h-mbt"},"outputs":[],"source":["def update_audio_paths(batch):\n","    # Generate full path for each audio file\n","    batch['audio'] = [\n","        {'path': os.path.join(audio_base_path, filepath),\n","         'array': audio['array'],\n","         'sampling_rate': audio['sampling_rate']}\n","        for filepath, audio in zip(batch['filepath'], batch['audio'])\n","    ]\n","    return batch\n","\n","# Apply the preprocessing function to the dataset\n","ds = ds.map(update_audio_paths, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"VkLoL_EM-mbt"},"source":["### Remove the unused columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"symZgZwh-mbt"},"outputs":[],"source":["ds = ds.remove_columns([\"text_translated\", \"intent\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlU_0WFK-mbt","executionInfo":{"status":"ok","timestamp":1731062520764,"user_tz":-420,"elapsed":2,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"eb9d9a23-11c6-4625-d457-3b0ea22c2fba"},"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['filepath', 'text_asr', 'audio'],\n","        num_rows: 450\n","    })\n","    test: Dataset({\n","        features: ['filepath', 'text_asr', 'audio'],\n","        num_rows: 57\n","    })\n","    valid: Dataset({\n","        features: ['filepath', 'text_asr', 'audio'],\n","        num_rows: 56\n","    })\n","})\n"]}],"source":["minds_fix = ds\n","print(minds_fix)"]},{"cell_type":"markdown","metadata":{"id":"QBd-YAjQ-mbt"},"source":["## Audio Augmentation and Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xcKcLyVf-mbt","executionInfo":{"status":"ok","timestamp":1731062545406,"user_tz":-420,"elapsed":19512,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"fdef0e91-80b0-46a3-e1bf-55beefdc44d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'array': [0.0,\n","  0.0,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.000244140625,\n","  0.000244140625,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.0,\n","  0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.0,\n","  0.000244140625,\n","  0.000244140625,\n","  0.000244140625,\n","  0.000244140625,\n","  0.000244140625,\n","  0.000244140625,\n","  0.000244140625,\n","  0.00048828125,\n","  0.000732421875,\n","  0.00048828125,\n","  0.000732421875,\n","  0.00048828125,\n","  0.0009765625,\n","  0.00048828125,\n","  0.0009765625,\n","  0.0,\n","  0.002197265625,\n","  0.003662109375,\n","  0.0029296875,\n","  0.00341796875,\n","  0.002685546875,\n","  0.002685546875,\n","  0.002197265625,\n","  0.003173828125,\n","  0.002685546875,\n","  0.001953125,\n","  0.002197265625,\n","  0.002197265625,\n","  0.001220703125,\n","  0.00146484375,\n","  0.0,\n","  -0.000732421875,\n","  -0.0009765625,\n","  0.00146484375,\n","  0.000244140625,\n","  0.0009765625,\n","  0.00048828125,\n","  -0.000732421875,\n","  -0.0009765625,\n","  -0.001953125,\n","  -0.001708984375,\n","  -0.002685546875,\n","  -0.00146484375,\n","  -0.00244140625,\n","  -0.002685546875,\n","  -0.0040283203125,\n","  -0.00341796875,\n","  -0.0040283203125,\n","  -0.0045166015625,\n","  -0.0050048828125,\n","  -0.0045166015625,\n","  -0.0040283203125,\n","  -0.002685546875,\n","  -0.00244140625,\n","  -0.0029296875,\n","  -0.0045166015625,\n","  -0.0045166015625,\n","  -0.003662109375,\n","  -0.00341796875,\n","  -0.00341796875,\n","  -0.0040283203125,\n","  -0.003662109375,\n","  -0.0045166015625,\n","  -0.0029296875,\n","  -0.0050048828125,\n","  -0.0050048828125,\n","  -0.0054931640625,\n","  -0.003662109375,\n","  -0.0029296875,\n","  -0.002197265625,\n","  -0.001953125,\n","  -0.00244140625,\n","  -0.002685546875,\n","  -0.001708984375,\n","  -0.001708984375,\n","  -0.001953125,\n","  -0.001953125,\n","  -0.001708984375,\n","  -0.0009765625,\n","  -0.00048828125,\n","  -0.000244140625,\n","  -0.001708984375,\n","  -0.000732421875,\n","  -0.00146484375,\n","  0.0009765625,\n","  0.000244140625,\n","  0.001953125,\n","  0.00146484375,\n","  0.00146484375,\n","  0.001708984375,\n","  0.001220703125,\n","  0.00146484375,\n","  0.001708984375,\n","  0.001953125,\n","  0.00146484375,\n","  0.00146484375,\n","  0.001220703125,\n","  0.00146484375,\n","  0.001708984375,\n","  0.002197265625,\n","  0.001220703125,\n","  0.002685546875,\n","  0.001953125,\n","  0.003662109375,\n","  0.003173828125,\n","  0.0040283203125,\n","  0.00341796875,\n","  0.0040283203125,\n","  0.0040283203125,\n","  0.00341796875,\n","  0.0045166015625,\n","  0.003662109375,\n","  0.003662109375,\n","  0.00244140625,\n","  0.00341796875,\n","  0.0029296875,\n","  0.0045166015625,\n","  0.0040283203125,\n","  0.0040283203125,\n","  0.002197265625,\n","  0.00244140625,\n","  0.001708984375,\n","  0.003173828125,\n","  0.0029296875,\n","  0.00341796875,\n","  0.0029296875,\n","  0.002197265625,\n","  0.00341796875,\n","  0.002685546875,\n","  0.00341796875,\n","  0.001953125,\n","  0.002197265625,\n","  0.00146484375,\n","  0.0029296875,\n","  0.002197265625,\n","  0.001953125,\n","  0.0,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.000732421875,\n","  0.001708984375,\n","  0.002197265625,\n","  0.001708984375,\n","  0.000732421875,\n","  0.001220703125,\n","  0.000244140625,\n","  0.0009765625,\n","  0.0,\n","  0.00048828125,\n","  -0.000732421875,\n","  -0.000732421875,\n","  -0.000244140625,\n","  0.0,\n","  -0.0009765625,\n","  -0.00146484375,\n","  -0.002197265625,\n","  -0.0009765625,\n","  0.0,\n","  0.00048828125,\n","  0.000244140625,\n","  -0.00146484375,\n","  -0.001708984375,\n","  -0.00244140625,\n","  -0.001708984375,\n","  -0.00146484375,\n","  -0.00146484375,\n","  -0.001220703125,\n","  -0.001220703125,\n","  -0.001953125,\n","  -0.002197265625,\n","  -0.0029296875,\n","  -0.00341796875,\n","  -0.0040283203125,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.00341796875,\n","  -0.0045166015625,\n","  -0.0045166015625,\n","  -0.0045166015625,\n","  -0.0045166015625,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.003662109375,\n","  -0.003662109375,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.0040283203125,\n","  -0.0050048828125,\n","  -0.0045166015625,\n","  -0.0050048828125,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.00341796875,\n","  -0.003662109375,\n","  -0.00341796875,\n","  -0.0040283203125,\n","  -0.00341796875,\n","  -0.003662109375,\n","  -0.00244140625,\n","  -0.002197265625,\n","  -0.0029296875,\n","  -0.002685546875,\n","  -0.003173828125,\n","  -0.001953125,\n","  -0.001953125,\n","  -0.00146484375,\n","  -0.001708984375,\n","  -0.000732421875,\n","  -0.0009765625,\n","  -0.000244140625,\n","  -0.00048828125,\n","  -0.00048828125,\n","  -0.001220703125,\n","  -0.0009765625,\n","  -0.0009765625,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.0,\n","  0.00048828125,\n","  0.000732421875,\n","  0.000244140625,\n","  0.0009765625,\n","  0.00048828125,\n","  0.001220703125,\n","  0.00048828125,\n","  0.001220703125,\n","  0.001220703125,\n","  0.001220703125,\n","  0.001220703125,\n","  0.00146484375,\n","  0.000732421875,\n","  0.001953125,\n","  0.00146484375,\n","  0.002197265625,\n","  0.00244140625,\n","  0.00244140625,\n","  0.002197265625,\n","  0.00244140625,\n","  0.0029296875,\n","  0.0029296875,\n","  0.003662109375,\n","  0.00341796875,\n","  0.0045166015625,\n","  0.0040283203125,\n","  0.0050048828125,\n","  0.0045166015625,\n","  0.0040283203125,\n","  0.003662109375,\n","  0.0040283203125,\n","  0.0040283203125,\n","  0.0045166015625,\n","  0.0040283203125,\n","  0.0045166015625,\n","  0.0040283203125,\n","  0.003662109375,\n","  0.00341796875,\n","  0.0040283203125,\n","  0.00341796875,\n","  0.00341796875,\n","  0.003173828125,\n","  0.002685546875,\n","  0.003662109375,\n","  0.002197265625,\n","  0.002685546875,\n","  0.002685546875,\n","  0.002685546875,\n","  0.0029296875,\n","  0.003173828125,\n","  0.001953125,\n","  0.001953125,\n","  0.001708984375,\n","  0.001953125,\n","  0.001708984375,\n","  0.00146484375,\n","  0.0009765625,\n","  0.001220703125,\n","  0.00048828125,\n","  0.00048828125,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.00048828125,\n","  -0.000732421875,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.0,\n","  -0.0009765625,\n","  -0.001953125,\n","  -0.00146484375,\n","  -0.001220703125,\n","  -0.000732421875,\n","  -0.000244140625,\n","  0.000244140625,\n","  -0.00048828125,\n","  -0.0009765625,\n","  -0.001220703125,\n","  -0.0009765625,\n","  -0.00048828125,\n","  -0.0009765625,\n","  -0.001708984375,\n","  -0.0029296875,\n","  -0.0029296875,\n","  -0.001953125,\n","  -0.00146484375,\n","  -0.001953125,\n","  -0.00244140625,\n","  -0.0029296875,\n","  -0.002685546875,\n","  -0.00244140625,\n","  -0.002685546875,\n","  -0.002685546875,\n","  -0.00244140625,\n","  -0.00341796875,\n","  -0.003662109375,\n","  -0.003662109375,\n","  -0.0029296875,\n","  -0.001953125,\n","  -0.0029296875,\n","  -0.0040283203125,\n","  -0.0050048828125,\n","  -0.0045166015625,\n","  -0.003662109375,\n","  -0.0029296875,\n","  -0.003173828125,\n","  -0.003662109375,\n","  -0.0045166015625,\n","  -0.0045166015625,\n","  -0.0040283203125,\n","  -0.003173828125,\n","  -0.002685546875,\n","  -0.003173828125,\n","  -0.003662109375,\n","  -0.003173828125,\n","  -0.002685546875,\n","  -0.001708984375,\n","  -0.001708984375,\n","  -0.0029296875,\n","  -0.00244140625,\n","  -0.001953125,\n","  -0.001220703125,\n","  -0.0009765625,\n","  -0.00146484375,\n","  -0.001220703125,\n","  -0.001708984375,\n","  -0.0009765625,\n","  -0.000732421875,\n","  -0.00048828125,\n","  0.000244140625,\n","  0.000732421875,\n","  0.0009765625,\n","  0.000732421875,\n","  -0.00048828125,\n","  -0.00146484375,\n","  -0.0009765625,\n","  0.000732421875,\n","  0.001953125,\n","  0.002197265625,\n","  0.002197265625,\n","  0.0009765625,\n","  0.00146484375,\n","  0.001953125,\n","  0.002685546875,\n","  0.0029296875,\n","  0.00146484375,\n","  0.001220703125,\n","  0.00146484375,\n","  0.002685546875,\n","  0.003173828125,\n","  0.0029296875,\n","  0.001708984375,\n","  0.000244140625,\n","  0.001953125,\n","  0.00341796875,\n","  0.0040283203125,\n","  0.003662109375,\n","  0.001708984375,\n","  0.000732421875,\n","  0.001220703125,\n","  0.00244140625,\n","  0.003173828125,\n","  0.0029296875,\n","  0.002197265625,\n","  0.002197265625,\n","  0.00244140625,\n","  0.00341796875,\n","  0.003173828125,\n","  0.00244140625,\n","  0.002197265625,\n","  0.001220703125,\n","  0.00244140625,\n","  0.003662109375,\n","  0.003662109375,\n","  0.003173828125,\n","  0.001953125,\n","  0.001708984375,\n","  0.001953125,\n","  0.003662109375,\n","  0.0040283203125,\n","  0.003173828125,\n","  0.00244140625,\n","  0.001708984375,\n","  0.002197265625,\n","  0.001708984375,\n","  0.001708984375,\n","  0.001220703125,\n","  0.0009765625,\n","  0.000732421875,\n","  0.00146484375,\n","  0.001953125,\n","  0.001953125,\n","  0.0009765625,\n","  0.000244140625,\n","  -0.00048828125,\n","  0.00048828125,\n","  0.000732421875,\n","  0.001220703125,\n","  0.001220703125,\n","  0.000244140625,\n","  -0.0009765625,\n","  -0.001220703125,\n","  0.000244140625,\n","  0.0009765625,\n","  0.000732421875,\n","  0.000244140625,\n","  -0.000732421875,\n","  -0.0009765625,\n","  -0.000244140625,\n","  -0.000732421875,\n","  -0.0009765625,\n","  -0.001708984375,\n","  -0.001953125,\n","  -0.00146484375,\n","  -0.001708984375,\n","  -0.001708984375,\n","  -0.00244140625,\n","  -0.003173828125,\n","  -0.00341796875,\n","  -0.0029296875,\n","  -0.00244140625,\n","  -0.002197265625,\n","  -0.00244140625,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.0029296875,\n","  -0.003173828125,\n","  -0.0029296875,\n","  -0.00341796875,\n","  -0.0040283203125,\n","  -0.0040283203125,\n","  -0.003662109375,\n","  -0.00341796875,\n","  -0.0045166015625,\n","  -0.0050048828125,\n","  -0.0040283203125,\n","  -0.0045166015625,\n","  -0.003662109375,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.0045166015625,\n","  -0.0045166015625,\n","  -0.0040283203125,\n","  -0.0029296875,\n","  -0.00244140625,\n","  -0.0029296875,\n","  -0.0029296875,\n","  -0.003173828125,\n","  -0.002685546875,\n","  -0.002197265625,\n","  -0.001953125,\n","  -0.001953125,\n","  -0.00146484375,\n","  -0.001708984375,\n","  -0.001220703125,\n","  -0.0009765625,\n","  -0.00048828125,\n","  -0.000732421875,\n","  -0.0009765625,\n","  -0.000732421875,\n","  -0.000244140625,\n","  -0.000244140625,\n","  0.0,\n","  0.000244140625,\n","  -0.000244140625,\n","  0.000244140625,\n","  0.00048828125,\n","  0.0009765625,\n","  0.001708984375,\n","  0.001953125,\n","  0.001220703125,\n","  0.00048828125,\n","  0.000244140625,\n","  0.001220703125,\n","  0.002685546875,\n","  0.002685546875,\n","  0.002197265625,\n","  0.001953125,\n","  0.00146484375,\n","  0.002197265625,\n","  0.00341796875,\n","  0.0040283203125,\n","  0.00341796875,\n","  0.002197265625,\n","  0.00146484375,\n","  0.00244140625,\n","  0.00341796875,\n","  0.0040283203125,\n","  0.00341796875,\n","  0.001953125,\n","  0.001708984375,\n","  0.002685546875,\n","  0.0040283203125,\n","  0.0045166015625,\n","  0.0029296875,\n","  0.001953125,\n","  0.00244140625,\n","  0.003662109375,\n","  0.0054931640625,\n","  0.0045166015625,\n","  0.003662109375,\n","  0.002197265625,\n","  0.00244140625,\n","  0.003173828125,\n","  0.0045166015625,\n","  0.0045166015625,\n","  0.003662109375,\n","  0.002685546875,\n","  0.002197265625,\n","  0.0029296875,\n","  0.00341796875,\n","  0.0029296875,\n","  0.001953125,\n","  0.00146484375,\n","  0.001708984375,\n","  0.00244140625,\n","  0.00244140625,\n","  0.002197265625,\n","  0.0009765625,\n","  0.000732421875,\n","  0.000732421875,\n","  0.001953125,\n","  0.002197265625,\n","  0.00146484375,\n","  0.000244140625,\n","  -0.001220703125,\n","  -0.0009765625,\n","  -0.00048828125,\n","  -0.00048828125,\n","  0.00048828125,\n","  -0.000732421875,\n","  -0.000732421875,\n","  -0.000244140625,\n","  0.0,\n","  -0.000244140625,\n","  -0.00146484375,\n","  -0.001220703125,\n","  -0.000732421875,\n","  -0.000732421875,\n","  -0.000732421875,\n","  -0.000244140625,\n","  -0.001220703125,\n","  -0.0009765625,\n","  -0.00244140625,\n","  -0.00244140625,\n","  -0.001220703125,\n","  -0.000732421875,\n","  -0.001220703125,\n","  -0.002197265625,\n","  -0.003173828125,\n","  -0.003662109375,\n","  -0.00341796875,\n","  -0.0029296875,\n","  -0.0029296875,\n","  -0.00341796875,\n","  -0.00341796875,\n","  -0.003662109375,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.00341796875,\n","  -0.0040283203125,\n","  -0.0045166015625,\n","  -0.0040283203125,\n","  -0.0040283203125,\n","  -0.003173828125,\n","  -0.003662109375,\n","  -0.0040283203125,\n","  -0.0040283203125,\n","  -0.003173828125,\n","  -0.00341796875,\n","  -0.003173828125,\n","  -0.003662109375,\n","  -0.003662109375,\n","  -0.003662109375,\n","  -0.002685546875,\n","  -0.002197265625,\n","  -0.002197265625,\n","  -0.00244140625,\n","  -0.00244140625,\n","  -0.001708984375,\n","  -0.000732421875,\n","  -0.0009765625,\n","  -0.001953125,\n","  -0.00244140625,\n","  -0.002197265625,\n","  -0.0009765625,\n","  -0.000244140625,\n","  -0.00048828125,\n","  -0.002197265625,\n","  -0.001953125,\n","  -0.0009765625,\n","  0.000732421875,\n","  0.000732421875,\n","  -0.00048828125,\n","  -0.001220703125,\n","  -0.001220703125,\n","  0.0,\n","  0.000244140625,\n","  0.000732421875,\n","  0.00048828125,\n","  0.000732421875,\n","  0.00048828125,\n","  0.001220703125,\n","  0.001708984375,\n","  0.001708984375,\n","  0.001220703125,\n","  0.0009765625,\n","  0.00146484375,\n","  0.002197265625,\n","  0.0029296875,\n","  0.002685546875,\n","  0.001953125,\n","  0.00146484375,\n","  0.001953125,\n","  0.002685546875,\n","  0.003662109375,\n","  0.0029296875,\n","  0.002197265625,\n","  0.001953125,\n","  0.0029296875,\n","  0.00341796875,\n","  0.003173828125,\n","  0.002685546875,\n","  0.002197265625,\n","  0.002197265625,\n","  0.003662109375,\n","  0.0045166015625,\n","  0.0050048828125,\n","  0.003662109375,\n","  0.00244140625,\n","  0.0029296875,\n","  0.0040283203125,\n","  0.0054931640625,\n","  0.0050048828125,\n","  0.00341796875,\n","  0.002685546875,\n","  0.00244140625,\n","  ...],\n"," 'path': '/content/drive/MyDrive/ai-portfolio/project3/datasets/MInDS-14/audio/en-US~FREEZE/602baeca5f67b421554f64c1.wav',\n"," 'sampling_rate': 8000}"]},"metadata":{},"execution_count":16}],"source":["# Checking the structure of audio data\n","ds['train']['audio'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"70kABhHb-mbt"},"outputs":[],"source":["import numpy as np\n","import librosa\n","from scipy.signal import medfilt\n","\n","def spectral_gate(audio, sr, threshold=1e-5):\n","    \"\"\"\n","    Simple spectral gating function to reduce noise.\n","    \"\"\"\n","    # Short-time Fourier Transform\n","    stft = librosa.stft(audio)\n","    magnitude, phase = librosa.magphase(stft)\n","\n","    # Median filter for estimating the noise floor\n","    noise_floor = medfilt(np.abs(magnitude), kernel_size=3)\n","\n","    # Suppress below the threshold\n","    magnitude[magnitude < threshold * noise_floor] = 0\n","\n","    # Reconstruct the signal\n","    return librosa.istft(magnitude * phase)\n","\n","def preprocess_audio_data(batch):\n","    audio_signals = []\n","    sample_rates = []\n","    for audio in batch['audio']:\n","        # Load audio and apply pre-emphasis\n","\n","        audio_signal, sr = librosa.load(audio['path'], sr=16000)\n","        audio_signal = librosa.effects.preemphasis(audio_signal)\n","\n","        # Normalize audio signal\n","        audio_signal = librosa.util.normalize(audio_signal)\n","\n","        # Denoise the audio signal using spectral gating\n","        audio_signal = spectral_gate(audio_signal, sr)\n","\n","        audio_signals.append(audio_signal)\n","        sample_rates.append(sr)\n","\n","    batch['audio'] = [{'array': signal, 'sampling_rate': sr} for signal, sr in zip(audio_signals, sample_rates)]\n","    return batch\n","\n","# Apply the preprocessing function to the dataset\n","ds = ds.map(preprocess_audio_data, batched=True, num_proc=4)"]},{"cell_type":"code","source":["def prepare_dataset(batch):\n","    # load and resample audio data from 48 to 16kHz\n","    audio = batch[\"audio\"]\n","\n","    # compute log-Mel input features from input audio array\n","    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n","\n","    # encode target text to label ids\n","    batch[\"labels\"] = tokenizer(batch[\"text_asr\"]).input_ids\n","    return batch"],"metadata":{"id":"TOVVchNqDH7s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Setting up Feature Extraction, Tokenizer, Voice Model, etc.\n","from transformers import WhisperTokenizer, WhisperFeatureExtractor, WhisperProcessor\n","MODEL_NAME = \"openai/whisper-small\"\n","tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME, language=\"english\", task=\"transcribe\")\n","feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME, language=\"english\", task=\"transcribe\")\n","processor = WhisperProcessor.from_pretrained(MODEL_NAME, language=\"english\", task=\"transcribe\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SjCSL0a9Dv7W","executionInfo":{"status":"ok","timestamp":1731059720946,"user_tz":-420,"elapsed":6704,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"dabf2b2f-2554-4f79-ca1c-5bebe831c35f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["ds = ds.map(prepare_dataset, remove_columns=ds.column_names[\"train\"], num_proc=4)"],"metadata":{"id":"g_X7uBT2DU79"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Setting up Voice Model"],"metadata":{"id":"xRwI-j2ZFTZM"}},{"cell_type":"code","source":["from transformers import WhisperForConditionalGeneration\n","model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)"],"metadata":{"id":"ULjCrOJLFQNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.generation_config.language = \"english\"\n","model.generation_config.task = \"transcribe\""],"metadata":{"id":"JZa5gibiFZZR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","@dataclass\n","class DataCollatorSpeechSeq2SeqWithPadding:\n","    processor: Any\n","    decoder_start_token_id: int\n","\n","    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n","        # split inputs and labels since they have to be of different lengths and need different padding methods\n","        # first treat the audio inputs by simply returning torch tensors\n","        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n","        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n","\n","        # get the tokenized label sequences\n","        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n","        # pad the labels to max length\n","        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n","\n","        # replace padding with -100 to ignore loss correctly\n","        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n","\n","        # if bos token is appended in previous tokenization step,\n","        # cut bos token here as it's append later anyways\n","        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n","            labels = labels[:, 1:]\n","\n","        batch[\"labels\"] = labels\n","\n","        return batch"],"metadata":{"id":"1kgTWF9pFg-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n","    processor=processor,\n","    decoder_start_token_id=model.config.decoder_start_token_id,\n",")"],"metadata":{"id":"Cl41fKRdFr9J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Defining Metrics and Do Training"],"metadata":{"id":"YNPS4XC8FvAU"}},{"cell_type":"code","source":["!pip install jiwer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8f5KF08GEpq","executionInfo":{"status":"ok","timestamp":1731059730645,"user_tz":-420,"elapsed":2444,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"4bfd0df0-0afc-454e-e1a7-48364ebd1824"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.5)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.10.1)\n"]}]},{"cell_type":"code","source":["import evaluate\n","metric = evaluate.load(\"wer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vzz8CAeFxDT","executionInfo":{"status":"ok","timestamp":1731062939128,"user_tz":-420,"elapsed":3544,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"11189118-143e-4679-ea8b-90540a003e8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def compute_metrics(pred):\n","    pred_ids = pred.predictions\n","    label_ids = pred.label_ids\n","\n","    # replace -100 with the pad_token_id\n","    label_ids[label_ids == -100] = tokenizer.pad_token_id\n","\n","    # we do not want to group tokens when computing the metrics\n","    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n","    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n","\n","    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n","\n","    return {\"wer\": wer}"],"metadata":{"id":"c1Jw6fnsGyS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainingArguments\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/ai-portfolio/project3/output\",\n","    gradient_accumulation_steps=4,  # increase by 2x for every 2x decrease in batch size\n","    learning_rate=5.6e-5,\n","    warmup_steps=4,\n","    max_steps=61,\n","    gradient_checkpointing=True,\n","    evaluation_strategy=\"steps\",\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    predict_with_generate=True,\n","    save_steps=8,\n","    eval_steps=8,\n","    logging_steps=8,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"wer\",\n","    greater_is_better=False,\n","    report_to=\"none\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvewzBWOF9JH","executionInfo":{"status":"ok","timestamp":1731059736286,"user_tz":-420,"elapsed":5,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"087a4f5e-1825-422f-8291-73062305eff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    args=training_args,\n","    model=model,\n","    train_dataset=ds[\"train\"],\n","    eval_dataset=ds[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=processor.feature_extractor,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W3fwpRmrGet-","executionInfo":{"status":"ok","timestamp":1731059736775,"user_tz":-420,"elapsed":491,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"49f7b9bc-c3ef-4d49-97b5-d1b4f8d542ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"code","source":["processor.save_pretrained(training_args.output_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFdDBYe7G775","executionInfo":{"status":"ok","timestamp":1731059737893,"user_tz":-420,"elapsed":1120,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"3f0c985a-c6f4-40f3-b61e-1f3246e3214f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["report_to=\"none\""],"metadata":{"id":"iIV8zqh8MCVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":991},"id":"bkX9PJqMG9Ki","executionInfo":{"status":"ok","timestamp":1731061441488,"user_tz":-420,"elapsed":1703596,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"8e77899a-6059-40f3-8364-633cbaf6512c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [61/61 28:00, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Wer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>8</td>\n","      <td>0.807700</td>\n","      <td>0.561277</td>\n","      <td>28.224101</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.427600</td>\n","      <td>0.548985</td>\n","      <td>23.150106</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.163400</td>\n","      <td>0.539813</td>\n","      <td>23.678647</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.103700</td>\n","      <td>0.565240</td>\n","      <td>24.630021</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.040000</td>\n","      <td>0.597726</td>\n","      <td>23.572939</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.012000</td>\n","      <td>0.638431</td>\n","      <td>19.873150</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.007300</td>\n","      <td>0.642267</td>\n","      <td>19.661734</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n","There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=61, training_loss=0.2050825156515739, metrics={'train_runtime': 1703.1922, 'train_samples_per_second': 1.146, 'train_steps_per_second': 0.036, 'total_flos': 5.5639265181696e+17, 'train_loss': 0.2050825156515739, 'epoch': 4.280701754385965})"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["## Making Evaluation and Do Inferencing"],"metadata":{"id":"goUHgFH3HHvF"}},{"cell_type":"markdown","source":["### Set Evaluation"],"metadata":{"id":"sEbNIoWtYK4l"}},{"cell_type":"code","source":["trainer_history = pd.DataFrame(trainer.state.log_history)\n","trainer_history.groupby('step').first().reset_index()\n","trainer_history"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":539},"id":"m6ULQ4NmHHP6","executionInfo":{"status":"ok","timestamp":1731061441488,"user_tz":-420,"elapsed":4,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"6b36d51b-5585-4238-f12d-b76d06875881"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      loss  grad_norm  learning_rate     epoch  step  eval_loss   eval_wer  \\\n","0   0.8077   7.345908       0.000052  0.561404     8        NaN        NaN   \n","1      NaN        NaN            NaN  0.561404     8   0.561277  28.224101   \n","2   0.4276   3.053201       0.000044  1.122807    16        NaN        NaN   \n","3      NaN        NaN            NaN  1.122807    16   0.548985  23.150106   \n","4   0.1634   2.800498       0.000036  1.684211    24        NaN        NaN   \n","5      NaN        NaN            NaN  1.684211    24   0.539813  23.678647   \n","6   0.1037   1.550972       0.000028  2.245614    32        NaN        NaN   \n","7      NaN        NaN            NaN  2.245614    32   0.565240  24.630021   \n","8   0.0400   1.316717       0.000021  2.807018    40        NaN        NaN   \n","9      NaN        NaN            NaN  2.807018    40   0.597726  23.572939   \n","10  0.0120   0.466597       0.000013  3.368421    48        NaN        NaN   \n","11     NaN        NaN            NaN  3.368421    48   0.638431  19.873150   \n","12  0.0073   0.401305       0.000005  3.929825    56        NaN        NaN   \n","13     NaN        NaN            NaN  3.929825    56   0.642267  19.661734   \n","14     NaN        NaN            NaN  4.280702    61        NaN        NaN   \n","\n","    eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n","0            NaN                      NaN                    NaN   \n","1        32.1404                    1.773                  0.249   \n","2            NaN                      NaN                    NaN   \n","3        35.0088                    1.628                  0.229   \n","4            NaN                      NaN                    NaN   \n","5        31.9299                    1.785                  0.251   \n","6            NaN                      NaN                    NaN   \n","7        32.5819                    1.749                  0.246   \n","8            NaN                      NaN                    NaN   \n","9        35.3498                    1.612                  0.226   \n","10           NaN                      NaN                    NaN   \n","11       32.4742                    1.755                  0.246   \n","12           NaN                      NaN                    NaN   \n","13       34.3620                    1.659                  0.233   \n","14           NaN                      NaN                    NaN   \n","\n","    train_runtime  train_samples_per_second  train_steps_per_second  \\\n","0             NaN                       NaN                     NaN   \n","1             NaN                       NaN                     NaN   \n","2             NaN                       NaN                     NaN   \n","3             NaN                       NaN                     NaN   \n","4             NaN                       NaN                     NaN   \n","5             NaN                       NaN                     NaN   \n","6             NaN                       NaN                     NaN   \n","7             NaN                       NaN                     NaN   \n","8             NaN                       NaN                     NaN   \n","9             NaN                       NaN                     NaN   \n","10            NaN                       NaN                     NaN   \n","11            NaN                       NaN                     NaN   \n","12            NaN                       NaN                     NaN   \n","13            NaN                       NaN                     NaN   \n","14      1703.1922                     1.146                   0.036   \n","\n","      total_flos  train_loss  \n","0            NaN         NaN  \n","1            NaN         NaN  \n","2            NaN         NaN  \n","3            NaN         NaN  \n","4            NaN         NaN  \n","5            NaN         NaN  \n","6            NaN         NaN  \n","7            NaN         NaN  \n","8            NaN         NaN  \n","9            NaN         NaN  \n","10           NaN         NaN  \n","11           NaN         NaN  \n","12           NaN         NaN  \n","13           NaN         NaN  \n","14  5.563927e+17    0.205083  "],"text/html":["\n","  <div id=\"df-3d2e3c5b-1b18-4870-a75f-1849b3aa4562\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>grad_norm</th>\n","      <th>learning_rate</th>\n","      <th>epoch</th>\n","      <th>step</th>\n","      <th>eval_loss</th>\n","      <th>eval_wer</th>\n","      <th>eval_runtime</th>\n","      <th>eval_samples_per_second</th>\n","      <th>eval_steps_per_second</th>\n","      <th>train_runtime</th>\n","      <th>train_samples_per_second</th>\n","      <th>train_steps_per_second</th>\n","      <th>total_flos</th>\n","      <th>train_loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.8077</td>\n","      <td>7.345908</td>\n","      <td>0.000052</td>\n","      <td>0.561404</td>\n","      <td>8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.561404</td>\n","      <td>8</td>\n","      <td>0.561277</td>\n","      <td>28.224101</td>\n","      <td>32.1404</td>\n","      <td>1.773</td>\n","      <td>0.249</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.4276</td>\n","      <td>3.053201</td>\n","      <td>0.000044</td>\n","      <td>1.122807</td>\n","      <td>16</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.122807</td>\n","      <td>16</td>\n","      <td>0.548985</td>\n","      <td>23.150106</td>\n","      <td>35.0088</td>\n","      <td>1.628</td>\n","      <td>0.229</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.1634</td>\n","      <td>2.800498</td>\n","      <td>0.000036</td>\n","      <td>1.684211</td>\n","      <td>24</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.684211</td>\n","      <td>24</td>\n","      <td>0.539813</td>\n","      <td>23.678647</td>\n","      <td>31.9299</td>\n","      <td>1.785</td>\n","      <td>0.251</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.1037</td>\n","      <td>1.550972</td>\n","      <td>0.000028</td>\n","      <td>2.245614</td>\n","      <td>32</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.245614</td>\n","      <td>32</td>\n","      <td>0.565240</td>\n","      <td>24.630021</td>\n","      <td>32.5819</td>\n","      <td>1.749</td>\n","      <td>0.246</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.0400</td>\n","      <td>1.316717</td>\n","      <td>0.000021</td>\n","      <td>2.807018</td>\n","      <td>40</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.807018</td>\n","      <td>40</td>\n","      <td>0.597726</td>\n","      <td>23.572939</td>\n","      <td>35.3498</td>\n","      <td>1.612</td>\n","      <td>0.226</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.0120</td>\n","      <td>0.466597</td>\n","      <td>0.000013</td>\n","      <td>3.368421</td>\n","      <td>48</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.368421</td>\n","      <td>48</td>\n","      <td>0.638431</td>\n","      <td>19.873150</td>\n","      <td>32.4742</td>\n","      <td>1.755</td>\n","      <td>0.246</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.0073</td>\n","      <td>0.401305</td>\n","      <td>0.000005</td>\n","      <td>3.929825</td>\n","      <td>56</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.929825</td>\n","      <td>56</td>\n","      <td>0.642267</td>\n","      <td>19.661734</td>\n","      <td>34.3620</td>\n","      <td>1.659</td>\n","      <td>0.233</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.280702</td>\n","      <td>61</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1703.1922</td>\n","      <td>1.146</td>\n","      <td>0.036</td>\n","      <td>5.563927e+17</td>\n","      <td>0.205083</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d2e3c5b-1b18-4870-a75f-1849b3aa4562')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3d2e3c5b-1b18-4870-a75f-1849b3aa4562 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3d2e3c5b-1b18-4870-a75f-1849b3aa4562');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bc3d9683-77ed-44fb-b250-a1bcb44c3b7d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc3d9683-77ed-44fb-b250-a1bcb44c3b7d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bc3d9683-77ed-44fb-b250-a1bcb44c3b7d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_65fc8b98-db21-41f9-923b-5debdd3725eb\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('trainer_history')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_65fc8b98-db21-41f9-923b-5debdd3725eb button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('trainer_history');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"trainer_history","summary":"{\n  \"name\": \"trainer_history\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2961014240650209,\n        \"min\": 0.0073,\n        \"max\": 0.8077,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8077,\n          0.4276,\n          0.012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grad_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.403942918932214,\n        \"min\": 0.4013046324253082,\n        \"max\": 7.345908164978027,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          7.345908164978027,\n          3.0532009601593018,\n          0.46659696102142334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.697878264846036e-05,\n        \"min\": 4.912280701754386e-06,\n        \"max\": 5.207017543859649e-05,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5.207017543859649e-05,\n          4.421052631578947e-05,\n          1.2771929824561402e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2396778077367412,\n        \"min\": 0.5614035087719298,\n        \"max\": 4.280701754385965,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.1228070175438596,\n          3.3684210526315788,\n          0.5614035087719298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 8,\n        \"max\": 61,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          16,\n          48,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.042008717410870325,\n        \"min\": 0.5398126840591431,\n        \"max\": 0.642267107963562,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.5612770915031433,\n          0.5489851832389832,\n          0.6384314894676208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_wer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.921834029827749,\n        \"min\": 19.661733615221987,\n        \"max\": 28.224101479915433,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          28.224101479915433,\n          23.150105708245245,\n          19.873150105708245\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4485202408303588,\n        \"min\": 31.9299,\n        \"max\": 35.3498,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          32.1404,\n          35.0088,\n          32.4742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07309517605085002,\n        \"min\": 1.612,\n        \"max\": 1.785,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.773,\n          1.628,\n          1.755\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01032795558988644,\n        \"min\": 0.226,\n        \"max\": 0.251,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.249,\n          0.229,\n          0.233\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1703.1922,\n        \"max\": 1703.1922,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1703.1922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.146,\n        \"max\": 1.146,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.036,\n        \"max\": 0.036,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.036\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_flos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 5.5639265181696e+17,\n        \"max\": 5.5639265181696e+17,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.5639265181696e+17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2050825156515739,\n        \"max\": 0.2050825156515739,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2050825156515739\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["### Plotting Evaluation"],"metadata":{"id":"JqpWS9WwHNsF"}},{"cell_type":"code","source":["# Plot WER over training steps\n","plt.figure(figsize=(12, 8))\n","\n","# Plot WER\n","plt.subplot(2, 1, 1)\n","plt.plot(trainer_history['step'], trainer_history['eval_wer'], marker='o', label='WER')\n","plt.title(\"WER over Training Steps\")\n","plt.xlabel(\"Steps\")\n","plt.ylabel(\"WER Evaluation\")\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"UexoFstHHO-q","executionInfo":{"status":"ok","timestamp":1731061442054,"user_tz":-420,"elapsed":569,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"5c836623-4b57-4576-871f-1d4303dcef7c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x800 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["### Setting Inference"],"metadata":{"id":"SWBsNm6_YRJc"}},{"cell_type":"code","source":["#inferencing\n","import time\n","from transformers import WhisperForConditionalGeneration, WhisperProcessor\n","\n","# Define the path to the model checkpoint (Choose the Lower WER Eval)\n","model_path = \"/content/drive/MyDrive/ai-portfolio/project3/output/checkpoint-56\"\n","\n","try:\n","    model = WhisperForConditionalGeneration.from_pretrained(model_path)\n","    processor = WhisperProcessor.from_pretrained(model_path)\n","    print(\"Model and processor loaded successfully.\")\n","except OSError as e:\n","    print(f\"Error loading model or processor: {e}\")\n","\n","def transcribe(audio):\n","    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features.to(\"cpu\")\n","\n","    forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"de\", task=\"transcribe\")\n","\n","    # Generate predictions and ensure the model's computations are on the correct device\n","    with torch.no_grad():\n","        predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n","\n","    # Decode the predictions into text\n","    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n","    return transcription[0]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ei8znvFTewW","executionInfo":{"status":"ok","timestamp":1731062456732,"user_tz":-420,"elapsed":2053,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"a58e5f73-256c-44b0-af64-5af612d3c96f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model and processor loaded successfully.\n"]}]},{"cell_type":"code","source":["from datasets import Audio\n","\n","minds_fix = minds_fix.cast_column(\"audio\", Audio(sampling_rate=16_000))"],"metadata":{"id":"yfWg83jsT7tx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inferencing"],"metadata":{"id":"W3kpMIQnYUo6"}},{"cell_type":"code","source":["# Run inference on five samples\n","for i in range(5):\n","    sample = minds_fix[\"test\"][i]\n","\n","    start_time = time.time()\n","    transcription = transcribe(sample[\"audio\"])\n","    end_time = time.time()\n","\n","    inference_time = end_time - start_time\n","\n","    print(f\"Sample {i+1}:\")\n","    print(f\"Reference: {sample['text_asr']}\")\n","    print(f\"Prediction: {transcription}\")\n","    print(f\"Inference time: {inference_time:.4f} seconds\")\n","    print()\n","\n","# Calculate overall WER for these five samples\n","wer = metric.compute(predictions=[transcribe(minds_fix[\"test\"][i][\"audio\"]) for i in range(5)],\n","                     references=[minds_fix[\"test\"][i][\"text_asr\"] for i in range(5)])\n","print(f\"WER for 5 samples: {wer}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNf5Vz9vYWAh","executionInfo":{"status":"ok","timestamp":1731063410465,"user_tz":-420,"elapsed":67585,"user":{"displayName":"Emir Al Shiqty","userId":"09525667683965186957"}},"outputId":"c473dbfb-8999-460e-8649-811bc759c04c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 1:\n","Reference: my card isn't working\n","Prediction: my card isn't working\n","Inference time: 5.2733 seconds\n","\n","Sample 2:\n","Reference: question but one of my recent transactions\n","Prediction: question about one of my recent transactions\n","Inference time: 6.2613 seconds\n","\n","Sample 3:\n","Reference: use the app and it is literally not working it's not showing my transactions for Sunday I'm trying to get you a bill and also check the status of a text that needs to be cleared and the app keeps closing it keeps crashing and it's not showing anything on my end\n","Prediction: hi I'm trying to use the app and it is literally not working it's not showing my transactions from Sunday I'm trying to pay a bill and also check the status of a check that needs to be cleared and the app keeps closing it keeps crashing and it's not showing anything on my end\n","Inference time: 9.6166 seconds\n","\n","Sample 4:\n","Reference: deposit money into my account how can I do that\n","Prediction: I'd like to deposit some money into my account\n","Inference time: 6.2313 seconds\n","\n","Sample 5:\n","Reference: my transactions aren't loading\n","Prediction: my transactions aren't loading\n","Inference time: 4.6759 seconds\n","\n","WER for 5 samples: 0.23376623376623376\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[],"collapsed_sections":["2Y66OzyDXya6","d7gIyI-B-mbp","pIqNb325-mbr","VkLoL_EM-mbt","sEbNIoWtYK4l"],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}